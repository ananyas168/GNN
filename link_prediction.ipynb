{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "link prediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP4xokIc3wK4v42XrtBh1GQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ananyas168/GNN/blob/main/link_prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYMrN6qdkkgJ",
        "outputId": "7102204e-d95a-4753-e166-28c1e4855676"
      },
      "source": [
        "!pip install dgl-cu110 \n",
        "import dgl\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import itertools\n",
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "%matplotlib inline\n",
        "!pip install scikit-plot\n",
        "import scikitplot as skplt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting dgl-cu110\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/e5/8536dc2f7048a91c63c913ece8c7b2e7f3e438e741aa4c2d847395486617/dgl_cu110-0.6.1-cp37-cp37m-manylinux1_x86_64.whl (39.9MB)\n",
            "\u001b[K     |████████████████████████████████| 39.9MB 33.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (2.23.0)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (1.19.5)\n",
            "Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu110) (2.5.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu110) (3.0.4)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx>=2.1->dgl-cu110) (4.4.2)\n",
            "Installing collected packages: dgl-cu110\n",
            "Successfully installed dgl-cu110-0.6.1\n",
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-plot\n",
            "  Downloading https://files.pythonhosted.org/packages/7c/47/32520e259340c140a4ad27c1b97050dd3254fdc517b1d59974d47037510e/scikit_plot-0.3.7-py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.9 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.10 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (1.0.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from scikit-plot) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scipy>=0.9->scikit-plot) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.8.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=1.4.0->scikit-plot) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=1.4.0->scikit-plot) (1.15.0)\n",
            "Installing collected packages: scikit-plot\n",
            "Successfully installed scikit-plot-0.3.7\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wwZe04wOkuen",
        "outputId": "7d29612f-4311-472c-b0de-c45fd551cdc9"
      },
      "source": [
        "import dgl.data\n",
        "\n",
        "dataset = dgl.data.CoraGraphDataset()\n",
        "g = dataset[0]\n",
        "g = dgl.add_self_loop(g)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading /root/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...\n",
            "Extracting file to /root/.dgl/cora_v2\n",
            "Finished data loading and preprocessing.\n",
            "  NumNodes: 2708\n",
            "  NumEdges: 10556\n",
            "  NumFeats: 1433\n",
            "  NumClasses: 7\n",
            "  NumTrainingSamples: 140\n",
            "  NumValidationSamples: 500\n",
            "  NumTestSamples: 1000\n",
            "Done saving data into cached files.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zBLMyUGgkw2e",
        "outputId": "a52efed3-9e4c-43a5-ec06-fb07745dd341"
      },
      "source": [
        "# Split edge set for training and testing\n",
        "print(g.edges())\n",
        "u, v = g.edges()\n",
        "print(len(u))\n",
        "print(len(v))\n",
        "eids = np.arange(g.number_of_edges())\n",
        "print(eids)\n",
        "eids = np.random.permutation(eids)\n",
        "print(len(eids))\n",
        "test_size = int(len(eids) * 0.1)\n",
        "train_size = g.number_of_edges() - test_size\n",
        "test_pos_u, test_pos_v = u[eids[:test_size]], v[eids[:test_size]]\n",
        "train_pos_u, train_pos_v = u[eids[test_size:]], v[eids[test_size:]]\n",
        "\n",
        "# Find all negative edges and split them for training and testing\n",
        "adj = sp.coo_matrix((np.ones(len(u)), (u.numpy(), v.numpy())))\n",
        "print(adj.todense())\n",
        "adj_neg = 1 - adj.todense() - np.eye(g.number_of_nodes())\n",
        "print(adj_neg)\n",
        "neg_u, neg_v = np.where(adj_neg != 0)\n",
        "print(len(neg_u))#, neg_v)\n",
        "print(g.number_of_edges())\n",
        "neg_eids = np.random.choice(len(neg_u), g.number_of_edges())\n",
        "test_neg_u, test_neg_v = neg_u[neg_eids[:test_size]], neg_v[neg_eids[:test_size]]\n",
        "train_neg_u, train_neg_v = neg_u[neg_eids[test_size:]], neg_v[neg_eids[test_size:]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([   0,    0,    0,  ..., 2705, 2706, 2707]), tensor([ 633, 1862, 2582,  ..., 2705, 2706, 2707]))\n",
            "13264\n",
            "13264\n",
            "[    0     1     2 ... 13261 13262 13263]\n",
            "13264\n",
            "[[1. 0. 0. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " [0. 1. 1. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 1. 0. 0.]\n",
            " [0. 0. 0. ... 0. 1. 1.]\n",
            " [0. 0. 0. ... 0. 1. 1.]]\n",
            "[[-1.  1.  1. ...  1.  1.  1.]\n",
            " [ 1. -1.  0. ...  1.  1.  1.]\n",
            " [ 1.  0. -1. ...  1.  1.  1.]\n",
            " ...\n",
            " [ 1.  1.  1. ... -1.  1.  1.]\n",
            " [ 1.  1.  1. ...  1. -1.  0.]\n",
            " [ 1.  1.  1. ...  1.  0. -1.]]\n",
            "7322708\n",
            "13264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-y7CjDsk5Hx"
      },
      "source": [
        "train_g = dgl.remove_edges(g, eids[:test_size])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOA7f4iZwM6v"
      },
      "source": [
        "from dgl.nn import SAGEConv\n",
        "\n",
        "# ----------- 2. create model -------------- #\n",
        "# build a two-layer GraphSAGE model\n",
        "class GraphSAGE(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GraphSAGE, self).__init__()\n",
        "        self.conv1 = SAGEConv(in_feats, h_feats, 'mean')\n",
        "        self.conv2 = SAGEConv(h_feats, h_feats, 'mean')\n",
        "\n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEWWqCEQPTZA"
      },
      "source": [
        "train_pos_g = dgl.graph((train_pos_u, train_pos_v), num_nodes=g.number_of_nodes())\n",
        "train_neg_g = dgl.graph((train_neg_u, train_neg_v), num_nodes=g.number_of_nodes())\n",
        "\n",
        "test_pos_g = dgl.graph((test_pos_u, test_pos_v), num_nodes=g.number_of_nodes())\n",
        "test_neg_g = dgl.graph((test_neg_u, test_neg_v), num_nodes=g.number_of_nodes())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4eBFpiUSDod"
      },
      "source": [
        "import dgl.function as fn\n",
        "import pandas as pd\n",
        "\n",
        "class DotPredictor(nn.Module):\n",
        "    def forward(self, g, h):\n",
        "        with g.local_scope():\n",
        "            g.ndata['h'] = h\n",
        "            # Compute a new edge feature named 'score' by a dot-product between the\n",
        "            # source node feature 'h' and destination node feature 'h'.\n",
        "            g.apply_edges(fn.u_dot_v('h', 'h', 'score'))\n",
        "            # u_dot_v returns a 1-element vector for each edge so you need to squeeze it.\n",
        "            return g.edata['score'][:, 0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZMnuUoiSir8"
      },
      "source": [
        "#model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
        "# You can replace DotPredictor with MLPPredictor.\n",
        "#pred = MLPPredictor(16)\n",
        "from sklearn.metrics import accuracy_score\n",
        "def train(train_g,train_pos_g,train_neg_g, model):\n",
        "    pred = DotPredictor()\n",
        "\n",
        "    train=[]\n",
        "    test=[]\n",
        "\n",
        "    def compute_loss(pos_score, neg_score):\n",
        "        scores = torch.cat([pos_score, neg_score])\n",
        "        labels = torch.cat([torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])])\n",
        "        #print(scores)\n",
        "        #print(labels)\n",
        "        return F.binary_cross_entropy_with_logits(scores, labels)\n",
        "\n",
        "    def compute_auc(pos_score, neg_score):\n",
        "        scores = torch.cat([pos_score, neg_score]).numpy()\n",
        "        \n",
        "        labels = torch.cat(\n",
        "            [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "        return roc_auc_score(labels, scores)\n",
        "    def accuracy(pos_score, neg_score):\n",
        "        scores = torch.cat([pos_score, neg_score]).detach().numpy()\n",
        "        scores = (scores>0.5)\n",
        "        labels = torch.cat(\n",
        "            [torch.ones(pos_score.shape[0]), torch.zeros(neg_score.shape[0])]).numpy()\n",
        "        print(scores)    \n",
        "        return accuracy_score(labels, scores)    \n",
        "    # ----------- 3. set up loss and optimizer -------------- #\n",
        "    # in this case, loss will in training loop\n",
        "    optimizer = torch.optim.Adam(itertools.chain(model.parameters(), pred.parameters()), lr=0.01)\n",
        "\n",
        "    # ----------- 4. training -------------------------------- #\n",
        "    all_logits = []\n",
        "    for e in range(100):\n",
        "        # forward\n",
        "        h = model(train_g, train_g.ndata['feat'])\n",
        "        pos_train_score = pred(train_pos_g, h)\n",
        "        print('pos_train_score',pos_train_score)\n",
        "        neg_train_score = pred(train_neg_g, h)\n",
        "        print('neg_train_score',neg_train_score)\n",
        "        loss = compute_loss(pos_train_score, neg_train_score)\n",
        "        # train_auc = compute_auc(pos_train_score, neg_train_score)\n",
        "        # pos_test_score = pred(test_pos_g, h)\n",
        "        # neg_test_score = pred(test_neg_g, h)\n",
        "        # test_loss = compute_loss(pos_test_score, neg_test_score)\n",
        "        # #test_auc = compute_auc(pos_test_score, neg_test_score)\n",
        "        # train.append(loss.item())\n",
        "        # test.append(test_loss.item())\n",
        "        \n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if e % 5 == 0:\n",
        "            print('In epoch {}, loss: {}'.format(e, loss))\n",
        "\n",
        "    # ----------- 5. check results ------------------------ #\n",
        "    # df= pd.DataFrame()\n",
        "    # df['test_loss']= test\n",
        "    # df['train_loss'] = train\n",
        "    \n",
        "    # print(df)\n",
        "    # ax = df.plot.line(rot=0,ylim=(0,1),figsize=[4,4],title='comparative_accuracy_plot')#,colormap='flare')\n",
        "    # #ax = bar_data.plot.bar(rot=0)\n",
        "    # #ax.label_outer('comparative_accuracy_bar_plot')\n",
        "    # fig=ax.get_figure()\n",
        "    # fig.savefig(path)\n",
        "    # ax.set_xlabel(\"iteration\")\n",
        "    # ax.set_ylabel(\"loss\")\n",
        "    from sklearn.metrics import roc_auc_score\n",
        "    with torch.no_grad():\n",
        "        pos_score = pred(test_pos_g, h)\n",
        "        neg_score = pred(test_neg_g, h)\n",
        "        print(neg_score)\n",
        "        print('AUC', compute_auc(pos_score, neg_score))\n",
        "        print('Auccuracy', accuracy(pos_score, neg_score))\n",
        "        #confusion_matrix(pos_score, neg_score)\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JafDpeVZ-A1G",
        "outputId": "b5878ef0-6efb-4764-c02e-20fefd12c275"
      },
      "source": [
        "model = GraphSAGE(train_g.ndata['feat'].shape[1], 16)\n",
        "train(train_g,train_pos_g,train_neg_g, model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "pos_train_score tensor([0.0029, 0.0020, 0.0007,  ..., 0.0032, 0.0066, 0.0023],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0007,  0.0012,  0.0006,  ...,  0.0008, -0.0003,  0.0005],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 0, loss: 0.6927748322486877\n",
            "pos_train_score tensor([0.0096, 0.0225, 0.0139,  ..., 0.0251, 0.0418, 0.0285],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([0.0120, 0.0156, 0.0121,  ..., 0.0123, 0.0071, 0.0012],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([0.0367, 0.0646, 0.0400,  ..., 0.0617, 0.1036, 0.1000],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([0.0379, 0.0441, 0.0280,  ..., 0.0384, 0.0179, 0.0190],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([0.0730, 0.0963, 0.0646,  ..., 0.0828, 0.1883, 0.2175],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([0.0538, 0.0566, 0.0111,  ..., 0.0478, 0.0084, 0.0436],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([0.1212, 0.1188, 0.0931,  ..., 0.0831, 0.3209, 0.4110],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0539,  0.0568, -0.0512,  ...,  0.0387, -0.0254,  0.0740],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([0.2097, 0.1441, 0.1285,  ..., 0.0872, 0.5012, 0.6920],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0582,  0.0589, -0.1685,  ...,  0.0231, -0.0807,  0.1282],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 5, loss: 0.6578933596611023\n",
            "pos_train_score tensor([0.3611, 0.1743, 0.1704,  ..., 0.1002, 0.7449, 1.0898],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0728,  0.0646, -0.3664,  ..., -0.0020, -0.1614,  0.2252],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([0.5715, 0.2040, 0.2308,  ..., 0.1232, 1.0906, 1.6495],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0863,  0.0785, -0.6655,  ..., -0.0377, -0.2807,  0.3675],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([0.8601, 0.2199, 0.3106,  ..., 0.1453, 1.5190, 2.3335],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.1015,  0.0894, -1.0874,  ..., -0.1016, -0.4264,  0.5859],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.1154, 0.2477, 0.4634,  ..., 0.1795, 2.1460, 3.2555],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0505,  0.1321, -1.5720,  ..., -0.1467, -0.6330,  0.7636],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.7295, 0.2634, 0.4704,  ..., 0.1565, 2.4238, 3.7169],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.1875,  0.0709, -2.1784,  ..., -0.3325, -0.7459,  1.2305],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 10, loss: 0.5711005926132202\n",
            "pos_train_score tensor([1.7675, 0.3311, 0.7579,  ..., 0.2372, 3.2080, 4.7364],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0087,  0.1931, -2.5106,  ..., -0.2842, -0.9486,  1.2161],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.0565, 0.3881, 0.8182,  ..., 0.2574, 3.4208, 5.0042],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0571,  0.1956, -2.7520,  ..., -0.3568, -0.9953,  1.4131],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.3794, 0.4649, 0.7924,  ..., 0.2672, 3.3264, 4.8543],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.2094,  0.1593, -2.8598,  ..., -0.4450, -0.9083,  1.6156],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.3087, 0.5562, 0.9035,  ..., 0.3594, 3.3992, 4.8461],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.1911,  0.2322, -2.7195,  ..., -0.3853, -0.8100,  1.5012],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.1417, 0.6804, 1.0252,  ..., 0.4632, 3.3798, 4.7143],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.1605,  0.3096, -2.4664,  ..., -0.2972, -0.6612,  1.2909],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 15, loss: 0.5256974101066589\n",
            "pos_train_score tensor([2.1118, 0.8558, 1.0240,  ..., 0.5232, 3.0912, 4.2799],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.2393,  0.3111, -2.2391,  ..., -0.2795, -0.4439,  1.1613],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.1168, 1.0737, 0.9895,  ..., 0.5814, 2.7464, 3.7943],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3422,  0.2959, -2.0206,  ..., -0.2766, -0.2529,  1.0213],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.0100, 1.3045, 1.0050,  ..., 0.6680, 2.5513, 3.4778],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3768,  0.3096, -1.7772,  ..., -0.2429, -0.1462,  0.7882],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.8469, 1.5438, 1.0537,  ..., 0.7719, 2.4805, 3.2999],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3546,  0.3380, -1.5382,  ..., -0.2026, -0.0755,  0.5321],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.7593, 1.7642, 1.0932,  ..., 0.8870, 2.4171, 3.1227],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3486,  0.3552, -1.3506,  ..., -0.1867, -0.0083,  0.3701],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 20, loss: 0.49729281663894653\n",
            "pos_train_score tensor([1.7820, 1.9350, 1.0811,  ..., 1.0163, 2.3258, 2.9159],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3925,  0.3638, -1.2251,  ..., -0.1876,  0.0411,  0.3259],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.8590, 2.0934, 1.0540,  ..., 1.1400, 2.2605, 2.7537],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4431,  0.3662, -1.1381,  ..., -0.1871,  0.0571,  0.3244],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.9259, 2.2752, 1.0521,  ..., 1.2264, 2.2742, 2.7013],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4549,  0.3598, -1.0666,  ..., -0.1781,  0.0344,  0.2949],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([1.9748, 2.4515, 1.0821,  ..., 1.3055, 2.3702, 2.7541],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4347,  0.3571, -0.9976,  ..., -0.1652, -0.0221,  0.2325],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.0549, 2.5748, 1.1333,  ..., 1.4183, 2.5034, 2.8443],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4213,  0.3684, -0.9493,  ..., -0.1586, -0.0786,  0.2033],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 25, loss: 0.47363218665122986\n",
            "pos_train_score tensor([2.2113, 2.6512, 1.1917,  ..., 1.5341, 2.6071, 2.9306],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4395,  0.3836, -0.9494,  ..., -0.1644, -0.1068,  0.2350],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.4365, 2.7333, 1.2474,  ..., 1.6185, 2.7073, 3.0271],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4795,  0.3832, -0.9983,  ..., -0.1771, -0.1178,  0.2932],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.6714, 2.8395, 1.3005,  ..., 1.6726, 2.8418, 3.1909],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5053,  0.3671, -1.0616,  ..., -0.1893, -0.1253,  0.3313],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.8598, 2.9166, 1.3825,  ..., 1.7259, 3.0363, 3.4426],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5001,  0.3574, -1.1047,  ..., -0.2008, -0.1435,  0.3485],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.0161, 2.9180, 1.4911,  ..., 1.7959, 3.2551, 3.7271],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4899,  0.3623, -1.1328,  ..., -0.2142, -0.1621,  0.3776],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 30, loss: 0.45557013154029846\n",
            "pos_train_score tensor([3.1872, 2.8718, 1.5898,  ..., 1.8699, 3.4245, 3.9604],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5130,  0.3623, -1.1740,  ..., -0.2339, -0.1616,  0.4309],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.3523, 2.8311, 1.6658,  ..., 1.9152, 3.5266, 4.1246],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5571,  0.3438, -1.2260,  ..., -0.2573, -0.1286,  0.4695],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.4407, 2.7987, 1.7564,  ..., 1.9254, 3.6098, 4.2667],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5761,  0.3132, -1.2528,  ..., -0.2793, -0.0869,  0.4544],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.4223, 2.7336, 1.8823,  ..., 1.9376, 3.7007, 4.4044],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5620,  0.2902, -1.2328,  ..., -0.3018, -0.0558,  0.3967],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.3507, 2.6272, 1.9824,  ..., 1.9732, 3.7603, 4.4872],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5565,  0.2832, -1.1926,  ..., -0.3273, -0.0292,  0.3327],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 35, loss: 0.43852007389068604\n",
            "pos_train_score tensor([3.2817, 2.5229, 2.0359,  ..., 2.0201, 3.7581, 4.4866],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5808,  0.2781, -1.1615,  ..., -0.3568,  0.0092,  0.2780],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.1970, 2.4612, 2.0849,  ..., 2.0512, 3.7361, 4.4518],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5996,  0.2585, -1.1361,  ..., -0.3917,  0.0614,  0.1979],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.0648, 2.4315, 2.1641,  ..., 2.0733, 3.7473, 4.4333],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5849,  0.2286, -1.0959,  ..., -0.4323,  0.1106,  0.0777],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.9170, 2.3926, 2.2542,  ..., 2.1239, 3.7880, 4.4291],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5656,  0.2102, -1.0406,  ..., -0.4777,  0.1459, -0.0388],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.8031, 2.3349, 2.3241,  ..., 2.2172, 3.8290, 4.4095],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5741,  0.2091, -1.0056,  ..., -0.5277,  0.1734, -0.1201],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 40, loss: 0.4199460744857788\n",
            "pos_train_score tensor([2.7222, 2.3016, 2.3929,  ..., 2.3171, 3.8718, 4.3775],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5899,  0.2012, -1.0000,  ..., -0.5836,  0.2107, -0.1951],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.6412, 2.3127, 2.4881,  ..., 2.3972, 3.9452, 4.3665],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5785,  0.1708, -1.0076,  ..., -0.6447,  0.2559, -0.2960],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5632, 2.3272, 2.5958,  ..., 2.4827, 4.0485, 4.3919],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5545,  0.1403, -1.0179,  ..., -0.7069,  0.2906, -0.4060],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5160, 2.3037, 2.6898,  ..., 2.5986, 4.1676, 4.4233],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5490,  0.1308, -1.0378,  ..., -0.7732,  0.3108, -0.4903],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5004, 2.2754, 2.7794,  ..., 2.7213, 4.2994, 4.4517],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5494,  0.1236, -1.0750,  ..., -0.8466,  0.3356, -0.5569],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 45, loss: 0.40240350365638733\n",
            "pos_train_score tensor([2.4960, 2.2896, 2.8797,  ..., 2.8128, 4.4480, 4.5017],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.5267,  0.0948, -1.1226,  ..., -0.9224,  0.3675, -0.6487],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.4990, 2.3210, 2.9799,  ..., 2.9035, 4.6123, 4.5839],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4965,  0.0615, -1.1703,  ..., -0.9976,  0.3920, -0.7440],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5204, 2.3217, 3.0730,  ..., 3.0359, 4.7855, 4.6621],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4829,  0.0481, -1.2180,  ..., -1.0785,  0.4070, -0.8050],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5466, 2.3178, 3.1846,  ..., 3.1842, 4.9623, 4.7217],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4649,  0.0380, -1.2682,  ..., -1.1680,  0.4346, -0.8548],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5675, 2.3566, 3.2891,  ..., 3.3027, 5.1214, 4.7904],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.4258,  0.0080, -1.3136,  ..., -1.2590,  0.4694, -0.9287],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 50, loss: 0.3835808038711548\n",
            "pos_train_score tensor([2.5908, 2.4116, 3.3458,  ..., 3.4097, 5.2515, 4.8694],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3855, -0.0257, -1.3447,  ..., -1.3504,  0.5022, -1.0045],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.6084, 2.4272, 3.4059,  ..., 3.5455, 5.3708, 4.9165],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3526, -0.0429, -1.3587,  ..., -1.4518,  0.5419, -1.0542],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.6052, 2.4406, 3.4857,  ..., 3.6790, 5.4769, 4.9502],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.3071, -0.0605, -1.3544,  ..., -1.5584,  0.5916, -1.1077],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5953, 2.4974, 3.5385,  ..., 3.7803, 5.5415, 5.0016],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.2486, -0.0956, -1.3432,  ..., -1.6625,  0.6476, -1.1821],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5910, 2.5457, 3.5843,  ..., 3.8907, 5.5799, 5.0435],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.1940, -0.1240, -1.3308,  ..., -1.7716,  0.7105, -1.2404],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 55, loss: 0.3651932179927826\n",
            "pos_train_score tensor([2.5770, 2.5579, 3.6576,  ..., 4.0210, 5.6336, 5.0705],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.1333, -0.1358, -1.3084,  ..., -1.8883,  0.7755, -1.2754],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5650, 2.5937, 3.7225,  ..., 4.1279, 5.6848, 5.1336],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([ 0.0640, -0.1553, -1.2850,  ..., -1.9754,  0.8376, -1.3154],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5762, 2.6610, 3.7708,  ..., 4.2169, 5.7171, 5.2194],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.0039, -0.1835, -1.2849,  ..., -2.0609,  0.9088, -1.3565],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.5983, 2.7058, 3.8469,  ..., 4.3313, 5.7698, 5.2937],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.0686, -0.1967, -1.3067,  ..., -2.1514,  0.9872, -1.3747],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.6131, 2.7481, 3.9279,  ..., 4.4502, 5.8552, 5.4048],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.1370, -0.2020, -1.3348,  ..., -2.2425,  1.0444, -1.3778],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 60, loss: 0.3469718098640442\n",
            "pos_train_score tensor([2.6405, 2.8247, 3.9911,  ..., 4.5397, 5.9472, 5.5614],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.2130, -0.2186, -1.3806,  ..., -2.3349,  1.0940, -1.3914],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.6851, 2.8958, 4.0642,  ..., 4.6251, 6.0426, 5.6976],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.2900, -0.2325, -1.4561,  ..., -2.4326,  1.1582, -1.4032],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.7321, 2.9464, 4.1389,  ..., 4.7182, 6.1582, 5.8452],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.3647, -0.2346, -1.5391,  ..., -2.5299,  1.2116, -1.4068],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.7658, 3.0095, 4.2060,  ..., 4.7874, 6.2906, 6.0390],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.4499, -0.2445, -1.6222,  ..., -2.6241,  1.2492, -1.4278],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.8052, 3.0789, 4.2664,  ..., 4.8321, 6.4137, 6.2230],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.5493, -0.2626, -1.7226,  ..., -2.7184,  1.2978, -1.4683],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 65, loss: 0.32833150029182434\n",
            "pos_train_score tensor([2.8594, 3.1349, 4.3024,  ..., 4.8802, 6.5249, 6.4110],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.6448, -0.2746, -1.8315,  ..., -2.8128,  1.3461, -1.5047],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.8936, 3.1907, 4.3494,  ..., 4.9167, 6.6427, 6.6359],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.7548, -0.2918, -1.9249,  ..., -2.9029,  1.3803, -1.5559],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.9214, 3.2464, 4.4105,  ..., 4.9482, 6.7362, 6.8576],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.8783, -0.3176, -2.0222,  ..., -2.9908,  1.4244, -1.6183],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([2.9768, 3.2993, 4.4487,  ..., 4.9920, 6.7948, 7.0913],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-0.9929, -0.3434, -2.1286,  ..., -3.0791,  1.4744, -1.6599],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.0092, 3.3475, 4.5184,  ..., 5.0333, 6.8848, 7.3465],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.1218, -0.3709, -2.2179,  ..., -3.1626,  1.5189, -1.7145],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 70, loss: 0.3092591166496277\n",
            "pos_train_score tensor([3.0309, 3.3952, 4.5994,  ..., 5.0813, 6.9745, 7.6134],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.2514, -0.4019, -2.3041,  ..., -3.2450,  1.5687, -1.7726],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.0704, 3.4382, 4.6674,  ..., 5.1546, 7.0283, 7.8853],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.3709, -0.4355, -2.4017,  ..., -3.3310,  1.6300, -1.8122],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.0989, 3.4669, 4.7714,  ..., 5.2291, 7.1123, 8.1741],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.5022, -0.4714, -2.4818,  ..., -3.4083,  1.6893, -1.8548],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.1348, 3.4917, 4.8815,  ..., 5.3043, 7.1934, 8.4784],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.6323, -0.5127, -2.5544,  ..., -3.4809,  1.7486, -1.8966],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.1963, 3.5099, 4.9839,  ..., 5.3916, 7.2419, 8.7708],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.7525, -0.5593, -2.6348,  ..., -3.5572,  1.8167, -1.9270],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 75, loss: 0.29035285115242004\n",
            "pos_train_score tensor([3.2485, 3.5145, 5.1181,  ..., 5.4747, 7.3125, 9.0614],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-1.8818, -0.6121, -2.6986,  ..., -3.6269,  1.8819, -1.9642],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.3086, 3.5178, 5.2339,  ..., 5.5586, 7.3797, 9.3772],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.0066, -0.6680, -2.7568,  ..., -3.6960,  1.9366, -1.9995],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.3809, 3.5009, 5.3652,  ..., 5.6509, 7.4395, 9.6434],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.1327, -0.7268, -2.8192,  ..., -3.7664,  2.0018, -2.0275],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([3.4528, 3.4971, 5.4836,  ..., 5.7350, 7.5039, 9.9419],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.2608, -0.7961, -2.8769,  ..., -3.8372,  2.0522, -2.0646],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 3.5268,  3.4760,  5.6250,  ...,  5.8247,  7.5873, 10.2024],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.3873, -0.8604, -2.9291,  ..., -3.9088,  2.0989, -2.0987],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 80, loss: 0.27104681730270386\n",
            "pos_train_score tensor([ 3.6185,  3.4643,  5.7465,  ...,  5.9206,  7.6500, 10.4685],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.4932, -0.9304, -2.9925,  ..., -3.9873,  2.1399, -2.1292],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 3.6996,  3.4552,  5.8876,  ...,  6.0111,  7.7405, 10.7403],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.6017, -1.0054, -3.0455,  ..., -4.0610,  2.1724, -2.1641],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 3.7969,  3.4463,  6.0147,  ...,  6.1204,  7.8211, 11.0229],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.6910, -1.0712, -3.1038,  ..., -4.1424,  2.1923, -2.1836],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 3.8845,  3.4464,  6.1594,  ...,  6.2186,  7.9194, 11.2948],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.7908, -1.1436, -3.1593,  ..., -4.2223,  2.2148, -2.2080],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 3.9810,  3.4690,  6.2700,  ...,  6.3195,  8.0028, 11.6209],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.8851, -1.2140, -3.2193,  ..., -4.3091,  2.2231, -2.2285],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 85, loss: 0.2517108917236328\n",
            "pos_train_score tensor([ 4.0693,  3.4624,  6.4327,  ...,  6.4378,  8.1208, 11.8738],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-2.9791, -1.2681, -3.2623,  ..., -4.3998,  2.2265, -2.2309],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.1765,  3.5187,  6.4942,  ...,  6.5341,  8.1997, 12.2470],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.0640, -1.3344, -3.3201,  ..., -4.4942,  2.1977, -2.2494],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.2467,  3.5045,  6.7181,  ...,  6.6467,  8.3751, 12.4515],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.1679, -1.3766, -3.3350,  ..., -4.5862,  2.2034, -2.2460],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.4000,  3.6232,  6.6578,  ...,  6.7653,  8.3893, 12.9723],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.2158, -1.4378, -3.4222,  ..., -4.6981,  2.1215, -2.2551],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.4047,  3.5299,  7.0634,  ...,  6.8641,  8.7105, 12.9938],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.3477, -1.4547, -3.3584,  ..., -4.7707,  2.1648, -2.2376],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 90, loss: 0.23315216600894928\n",
            "pos_train_score tensor([ 4.6345,  3.7987,  6.7652,  ...,  7.0024,  8.5708, 13.8087],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.3533, -1.5531, -3.5246,  ..., -4.9057,  2.0026, -2.2615],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.6070,  3.5643,  7.3233,  ...,  7.0622,  9.0249, 13.5988],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.4719, -1.5059, -3.3737,  ..., -4.9476,  2.0952, -2.2143],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.7822,  3.8646,  7.0769,  ...,  7.1552,  8.9314, 14.3653],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.5322, -1.6505, -3.5324,  ..., -5.0741,  1.9426, -2.2763],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.9025,  3.8132,  7.2875,  ...,  7.3260,  9.1089, 14.6327],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.5564, -1.6322, -3.5220,  ..., -5.1778,  1.9065, -2.2078],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 4.9330,  3.7891,  7.5730,  ...,  7.3254,  9.4397, 14.7961],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.6802, -1.6707, -3.4376,  ..., -5.2184,  1.9288, -2.2307],\n",
            "       grad_fn=<SelectBackward>)\n",
            "In epoch 95, loss: 0.2148917317390442\n",
            "pos_train_score tensor([ 5.1818,  4.0685,  7.3319,  ...,  7.4642,  9.3012, 15.5365],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.6879, -1.7805, -3.6299,  ..., -5.3703,  1.7815, -2.2477],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 5.2212,  3.9033,  7.7549,  ...,  7.5965,  9.6712, 15.6375],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.7497, -1.7387, -3.5164,  ..., -5.4417,  1.8024, -2.1598],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 5.3176,  4.0702,  7.7988,  ...,  7.6417,  9.8124, 16.1269],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.8564, -1.8517, -3.5741,  ..., -5.5284,  1.7446, -2.1937],\n",
            "       grad_fn=<SelectBackward>)\n",
            "pos_train_score tensor([ 5.5727,  4.1934,  7.7577,  ...,  7.8323,  9.7693, 16.6868],\n",
            "       grad_fn=<SelectBackward>)\n",
            "neg_train_score tensor([-3.8292, -1.8932, -3.7239,  ..., -5.6894,  1.6523, -2.1381],\n",
            "       grad_fn=<SelectBackward>)\n",
            "tensor([-1.3782, -2.3479, -2.8450,  ...,  1.7118, -0.6719,  0.7039])\n",
            "AUC 0.8840028527944419\n",
            "[ True  True  True ...  True False  True]\n",
            "Auccuracy 0.7677224736048266\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWYCMHfl-WCD",
        "outputId": "d7d733dd-d4d0-4a28-836d-5ce9cdee7db9"
      },
      "source": [
        "from dgl.nn import GraphConv\n",
        "g = dgl.add_self_loop(g)\n",
        "class GCN(nn.Module):\n",
        "    def __init__(self, in_feats, h_feats):\n",
        "        super(GCN, self).__init__()\n",
        "        self.conv1 = GraphConv(in_feats, h_feats, allow_zero_in_degree=True)\n",
        "        self.conv2 = GraphConv(h_feats, h_feats, allow_zero_in_degree=True)\n",
        "        \n",
        "    def forward(self, g, in_feat):\n",
        "        h = self.conv1(g, in_feat)\n",
        "        h = F.relu(h)\n",
        "        h = self.conv2(g, h)\n",
        "        return h\n",
        "\n",
        "     \n",
        "    #     class gin_conv(nn.Module):\n",
        "    # def __init__(self, in_feats, h_feats):\n",
        "    #     super(gin_conv, self).__init__()\n",
        "    #     self.conv1 =  GINConv(in_feats, h_feats, 'max')\n",
        "    #     self.conv2 = GINConv(h_feats, h_feats, 'max')\n",
        "\n",
        "    # def forward(self, g, in_feat):\n",
        "    #     h = self.conv1(g, in_feat)\n",
        "    #     h = F.relu(h)\n",
        "    #     h = self.conv2(g, h)\n",
        "    #     return h\n",
        "\n",
        "# Create the model with given dimensions\n",
        "model2 = GCN(train_g.ndata['feat'].shape[1], 16)\n",
        "train(train_g,train_pos_g,train_neg_g, model2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 0.6931235194206238\n",
            "In epoch 5, loss: 0.6827359795570374\n",
            "In epoch 10, loss: 0.6763810515403748\n",
            "In epoch 15, loss: 0.668129026889801\n",
            "In epoch 20, loss: 0.6570489406585693\n",
            "In epoch 25, loss: 0.6411725282669067\n",
            "In epoch 30, loss: 0.6169807314872742\n",
            "In epoch 35, loss: 0.5817654132843018\n",
            "In epoch 40, loss: 0.5407572984695435\n",
            "In epoch 45, loss: 0.5216805934906006\n",
            "In epoch 50, loss: 0.5121780633926392\n",
            "In epoch 55, loss: 0.501544177532196\n",
            "In epoch 60, loss: 0.49046215415000916\n",
            "In epoch 65, loss: 0.4792875051498413\n",
            "In epoch 70, loss: 0.4664355218410492\n",
            "In epoch 75, loss: 0.45692914724349976\n",
            "In epoch 80, loss: 0.45091113448143005\n",
            "In epoch 85, loss: 0.4439762532711029\n",
            "In epoch 90, loss: 0.43805623054504395\n",
            "In epoch 95, loss: 0.4325326979160309\n",
            "tensor([ 0.4324, -0.5252, -1.4770,  ...,  1.1590, -1.2474, -1.4790])\n",
            "AUC 0.8818285638887183\n",
            "[ True  True  True ...  True False False]\n",
            "Auccuracy 0.7816742081447964\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jGIk9h8-Ipo6",
        "outputId": "82ab8787-b083-4d85-9b63-a73b14ef3685"
      },
      "source": [
        "from dgl.nn.pytorch.conv import GATConv\n",
        "\n",
        "class GAT(torch.nn.Module):\n",
        "    def __init__(self, in_feats,hidden_dim,h_feats, num_heads):\n",
        "        super(GAT, self).__init__()\n",
        "        self.layer1 = GATConv(in_feats, hidden_dim, num_heads, allow_zero_in_degree=True)\n",
        "        self.layer2 = GATConv(hidden_dim * num_heads, h_feats, 1, allow_zero_in_degree=True)\n",
        "    def forward(self, g, h):\n",
        "        h = self.layer1(g, h)\n",
        "        h = h.view(-1, h.size(1) * h.size(2))\n",
        "        h = F.elu(h)\n",
        "        h = self.layer2(g, h)\n",
        "        h = h.squeeze() \n",
        "        return h\n",
        "\n",
        "model3 =GAT(train_g.ndata['feat'].shape[1], 16,30,2)\n",
        "train(train_g,train_pos_g,train_neg_g, model3)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "In epoch 0, loss: 0.6927238702774048\n",
            "In epoch 5, loss: 0.6795674562454224\n",
            "In epoch 10, loss: 0.6202573180198669\n",
            "In epoch 15, loss: 0.5692955255508423\n",
            "In epoch 20, loss: 0.5319256782531738\n",
            "In epoch 25, loss: 0.5131011605262756\n",
            "In epoch 30, loss: 0.4980435073375702\n",
            "In epoch 35, loss: 0.478251188993454\n",
            "In epoch 40, loss: 0.4710206985473633\n",
            "In epoch 45, loss: 0.4587682783603668\n",
            "In epoch 50, loss: 0.44706839323043823\n",
            "In epoch 55, loss: 0.43710261583328247\n",
            "In epoch 60, loss: 0.42780038714408875\n",
            "In epoch 65, loss: 0.4187321364879608\n",
            "In epoch 70, loss: 0.4091523289680481\n",
            "In epoch 75, loss: 0.3995278477668762\n",
            "In epoch 80, loss: 0.3898409307003021\n",
            "In epoch 85, loss: 0.38005444407463074\n",
            "In epoch 90, loss: 0.3705344498157501\n",
            "In epoch 95, loss: 0.36109089851379395\n",
            "tensor([ 0.7568,  0.2325, -2.2273,  ..., -0.0855, -0.4884, -2.2936])\n",
            "AUC 0.9234130477808946\n",
            "[ True  True  True ... False False False]\n",
            "Auccuracy 0.802790346907994\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}